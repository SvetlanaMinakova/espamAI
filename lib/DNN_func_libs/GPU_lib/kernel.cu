// File automatically generated by ESPAM

#include <stdio.h>
#include <cuda.h>
#include <cudnn.h>
#include <iostream>


#include <cuda_runtime.h>
#include <helper_functions.h>
#include <helper_cuda.h>

using namespace std;

#define checkCUDNN(expression)                               \
  {                                                          \
    cudnnStatus_t status = (expression);                     \
    if (status != CUDNN_STATUS_SUCCESS) {                    \
      std::cerr << "Error on line " << __LINE__ << ": "      \
                << cudnnGetErrorString(status) << std::endl; \
      std::exit(EXIT_FAILURE);                               \
    }                                                        \
  }

int iDivUp (int a, int b) { 
    return (a % b != 0) ? (a / b + 1) : (a / b);
} 




__global__ void kernel_3d(float *input, float *weights, float *output, float *bias, int channels, int input_h, int input_w, int output_d, int output_h, int output_w, int k_h, int k_w, int stride) {


  float fold_cell = 0;
  int input_elem_ind = 0;
  int k_elem_ind = 0;
  int k_elem_ind_reverse = 0;
  int k_size = k_h*k_w;
  int outp_elem_ind =0;
  int sub_kern_start = 0;

  float *sub_input;
  float *sub_output;
  float *sub_kernel;

  int i= blockIdx.x * blockDim.x + threadIdx.x;
  int j= blockIdx.y * blockDim.y + threadIdx.y;
  int ofm= blockIdx.z * blockDim.z + threadIdx.z;

//for (int ofm=0; ofm<output_d;ofm++){
  
  sub_output = output + output_w * output_h * ofm;
  for (int ifm=0; ifm<channels;ifm++){

    sub_input = input + input_w * input_h * ifm;
    sub_kern_start =  k_h * k_w * ifm + k_h * k_w * channels * ofm;
    //if(channels!=1){
    //std::cout<<"sub_k_start: "<<sub_kern_start<<std::endl;
//}
    sub_kernel = weights + sub_kern_start;



//     for (int j = 0; j < output_h; j++){
//     for (int i = 0; i < output_w; i++){

    	//std::cout<<std::endl<<std::endl<<"out["<<i<<"]["<<j<<"]"<<std::endl;

        fold_cell = 0;
         //summ k,l
        for (int l = 0; l < k_h; l++){
          for (int k = 0; k < k_w; k++){
            k_elem_ind = l + k * k_h;
            k_elem_ind_reverse = k_size - k_elem_ind - 1;
            input_elem_ind = (j*stride+l) + (i*stride+k)* input_w;
             fold_cell += *(sub_input + input_elem_ind) * *(sub_kernel + k_elem_ind);
          }
        }
        outp_elem_ind = i * output_w + j;
        sub_output[outp_elem_ind] += fold_cell;
        fold_cell = 0;
}
//}
//}
//}
}


 void print_2D(const int &h, const int &w, float *x)
    {
      int start_elem_id = 0;
        for (int i = 0; i < h; i++){
          for (int j = 0; j < w ; j++)
            std::cout << x[i * w + j + start_elem_id] << ' ';
          std::cout<<endl;
        }
        start_elem_id +=w*h;
      }
 




 void print_3D(const int &d, const int &h, const int &w, float *x)
    {
      int start_elem_id = 0;
      for(int depth=0; depth < d; depth++ ){
        std::cout<<"depth"<<depth<<endl;
        for (int i = 0; i < h; i++){
          for (int j = 0; j < w ; j++)
            std::cout << x[i * w + j + start_elem_id] << ' ';
          std::cout<<endl;
        }
        start_elem_id +=w*h;
      }
    }




void kernelhost_3d(float *input, float *weights, float *output, float *bias, int channels, int input_h, int input_w, int output_d, int output_h, int output_w, int k_h, int k_w, int stride, int pad_h, int pad_w){

 printf("..............1\n");

 	 //init output
	  if(bias==NULL){
	    for (int i = 0; i < output_d * output_h * output_w; i++)
	      output[i] = 0;
	    }
	  else {
	    float bias_val;
	    for (int d = 0; d < output_d; d++) {
	      bias_val = bias[d];
	      //std::cout<<" d: "<<d <<" ,bias_val "<<bias_val<<" ";
	      for (int i = 0; i < output_w * output_h; i++)
	        output[i + d * output_w * output_h] = bias_val;
	      }
	    }

  cudnnHandle_t cudnn;
  checkCUDNN(cudnnCreate(&cudnn));

//demonsion of output and kernel must be the same with input

cudnnTensorDescriptor_t output_descriptor;
checkCUDNN(cudnnCreateTensorDescriptor(&output_descriptor));
checkCUDNN(cudnnSetTensor4dDescriptor(output_descriptor,
                                      /*format=*/CUDNN_TENSOR_NHWC,
                                      /*dataType=*/CUDNN_DATA_FLOAT,
                                      /*batch_size=*/1,
                                      /*channels=*/output_d,
                                      /*image_height=*/output_h,
                                      /*image_width=*/output_w));


 printf("output_d= %d\n", output_d);
 printf("channels= %d\n", channels);
 printf("output demonsion= %d\n", output_d*output_h*output_w);
 printf("..............2\n");

cudnnTensorDescriptor_t input_descriptor;
checkCUDNN(cudnnCreateTensorDescriptor(&input_descriptor));
checkCUDNN(cudnnSetTensor4dDescriptor(input_descriptor,
                                      /*format=*/CUDNN_TENSOR_NHWC,
                                      /*dataType=*/CUDNN_DATA_FLOAT,
                                      /*batch_size=*/1,
                                      /*channels=*/channels,
                                      /*image_height=*/input_h - 2*pad_h,
                                      /*image_width=*/input_w - 2*pad_w));
 printf("..............2\n");
 printf("channels= %d\n", channels);
 printf("input_h= %d\n", input_h - 2*pad_h);
 printf("input_w= %d\n", input_w - 2*pad_w);
 printf("input demonsion= %d\n", channels*(input_h-2*pad_h)*(input_w-2*pad_w));

cudnnFilterDescriptor_t kernel_descriptor;
checkCUDNN(cudnnCreateFilterDescriptor(&kernel_descriptor));
checkCUDNN(cudnnSetFilter4dDescriptor(kernel_descriptor,
                                      /*dataType=*/CUDNN_DATA_FLOAT,
                                      /*format=*/CUDNN_TENSOR_NCHW,
                                      /*out_channels=*/output_d,
                                      /*in_channels=*/channels,
                                      /*kernel_height=*/k_h, 
                                     /*kernel_width=*/k_w));

 printf("..............4\n");
 printf("kernel demonsion= %d\n", output_d*channels*k_h*k_w);

cudnnConvolutionDescriptor_t convolution_descriptor;
checkCUDNN(cudnnCreateConvolutionDescriptor(&convolution_descriptor));
checkCUDNN(cudnnSetConvolution2dDescriptor(convolution_descriptor,
                                           /*pad_height=*/pad_h,
                                           /*pad_width=*/pad_w,
                                           /*vertical_stride=*/stride,
                                           /*horizontal_stride=*/stride,
                                           /*dilation_height=*/1,
                                           /*dilation_width=*/1,
                                           /*mode=*/CUDNN_CROSS_CORRELATION,
                                           /*computeType=*/CUDNN_DATA_FLOAT));

 printf("..............5\n");

if(input_descriptor==NULL)
	 printf(" convolution_descriptor IS NULL\n");

if(kernel_descriptor==NULL)
	 printf(" input_descriptor IS NULL\n");

if(convolution_descriptor==NULL)
	 printf(" convolution_descriptor IS NULL\n");

if(output_descriptor==NULL)
	 printf(" output_descriptor IS NULL\n");


cudnnConvolutionFwdAlgo_t convolution_algorithm;
checkCUDNN(
    cudnnGetConvolutionForwardAlgorithm(cudnn,
                                        input_descriptor,
                                        kernel_descriptor,
                                        convolution_descriptor,
                                        output_descriptor,
                                        CUDNN_CONVOLUTION_FWD_PREFER_FASTEST,
                                        /*memoryLimitInBytes=*/0,
                                        &convolution_algorithm));

 printf("..............6\n");

size_t workspace_bytes = 0;
checkCUDNN(cudnnGetConvolutionForwardWorkspaceSize(cudnn,
                                                   input_descriptor,
                                                   kernel_descriptor,
                                                   convolution_descriptor,
                                                   output_descriptor,
                                                   convolution_algorithm,
                                                   &workspace_bytes));
std::cerr << "Workspace size: " << (workspace_bytes / 1048576.0) << "MB"
          << std::endl;

 printf("..............7\n");

        //allocate memory

void* d_workspace=NULL;
cudaMalloc(&d_workspace, workspace_bytes);


int image_bytes = 1 * channels * output_h * output_w * sizeof(float);

float* d_input=NULL;
cudaMalloc(&d_input, image_bytes);
cudaMemcpy(d_input, input, image_bytes, cudaMemcpyHostToDevice);

float* d_output=NULL;
cudaMalloc(&d_output, image_bytes);
cudaMemset(d_output, 0, image_bytes);

/*
		int N_input = input_h * input_w * channels;
		int N_weights = k_h * k_w * output_d * channels;
		int N_output = output_d * output_h * output_w;

        float *d_input, *d_weights, *d_output;
		cudaMalloc(&d_input, N_input*sizeof(float));
		cudaMalloc(&d_weights, N_weights*sizeof(float));
		cudaMalloc(&d_output, N_output*sizeof(float));

		checkCudaErrors(cudaMemcpy(d_input, input, N_input*sizeof(float), cudaMemcpyHostToDevice));
		checkCudaErrors(cudaMemcpy(d_weights, weights, N_weights*sizeof(float), cudaMemcpyHostToDevice));
		checkCudaErrors(cudaMemcpy(d_output, output, N_output*sizeof(float), cudaMemcpyHostToDevice));


*/

 printf("..............9\n");

// Mystery kernel
const float kernel_template[3][3] = {
  {1,  1, 1},
  {1, -8, 1},
  {1,  1, 1}
};

float h_kernel[3][3][3][3];
for (int kernel = 0; kernel < 3; ++kernel) {
  for (int channel = 0; channel < 3; ++channel) {
    for (int row = 0; row < 3; ++row) {
      for (int column = 0; column < 3; ++column) {
        h_kernel[kernel][channel][row][column] = kernel_template[row][column];
      }
    }
  }
}

float* d_kernel=NULL;
cudaMalloc(&d_kernel, sizeof(h_kernel));
cudaMemcpy(d_kernel, h_kernel, sizeof(h_kernel), cudaMemcpyHostToDevice);

 printf("..............10\n");

const float alpha = 1, beta = 0;
checkCUDNN(cudnnConvolutionForward(cudnn,
                                   &alpha,
                                   input_descriptor,
                                   d_input,
                                   kernel_descriptor,
                                   d_kernel,
                                   convolution_descriptor,
                                   convolution_algorithm,
                                   d_workspace,
                                   workspace_bytes,
                                   &beta,
                                   output_descriptor,
                                   d_output))

 printf("..............11\n");
/*
       int blockW, blockH, blockD;
       int count_w=0, count_h=0, count_d=0, n_w=0, n_h=0, n_d=0, maxn=30;
       int approximate_w[maxn], approximate_h[maxn], approximate_d[maxn];

       while(count_w<=output_w){
         if(output_w%count_w == 0){
         approximate_w[n_w++]=count_w;
            }
          count_w++; 
          }
         if(n_w%2==0){
         blockW=approximate_w[n_w/2-1];
       }else{
         blockW=approximate_w[(n_w-1)/2];
       }         
 //      printf("blockW=%d\n", blockW);


       while(count_h<=output_h){
         if(output_h%count_h == 0){
         approximate_h[n_h++]=count_h;
            }
          count_h++; 
          }
         if(n_h%2==0){
         blockH=approximate_h[n_h/2-1];
       }else{
         blockH=approximate_h[(n_h-1)/2];
       }         
 //      printf("blockH=%d\n", blockH);


       while(count_d<=output_d){
         if(output_d%count_d == 0){
         approximate_d[n_d++]=count_d;
            }
          count_d++; 
          }
         if(n_d%2==0){
         blockD=approximate_d[n_d/2-1];
       }else{
         blockD=approximate_d[(n_d-1)/2];
       }         
//       printf("blockD=%d\n", blockD);



		dim3 dimBlock(blockW, blockH, blockD);
    		dim3 dimGrid(iDivUp(output_w, dimBlock.x), iDivUp(output_h, dimBlock.y), iDivUp(output_d, dimBlock.z));
                //cout<<"iDivUp(output_w, dimBlock.x)="<<iDivUp(output_w, dimBlock.x)<<endl;
		//cout<<"iDivUp(output_h, dimBlock.y)="<<iDivUp(output_h, dimBlock.y)<<endl;
		kernel_3d<<<dimGrid, dimBlock>>>(d_input, d_weights, d_output, bias, channels, input_h, input_w, output_d, output_h, output_w, k_h, k_w, stride);

		cudaDeviceSynchronize();

		checkCudaErrors(cudaMemcpy(output, d_output, N_output*sizeof(float), cudaMemcpyDeviceToHost));
     //	  cout<<"after computation:"<<endl;
     //	  print_3D(output_d, output_h, output_w, output);




		cudaFree(d_input);
		cudaFree(d_weights);
		cudaFree(d_output);
*/



cudaMemcpy(output, d_output, image_bytes, cudaMemcpyDeviceToHost);

// Do something with h_output ...

cudaFree(d_kernel);
cudaFree(d_input);
cudaFree(d_output);
cudaFree(d_workspace);

cudnnDestroyTensorDescriptor(input_descriptor);
cudnnDestroyTensorDescriptor(output_descriptor);
cudnnDestroyFilterDescriptor(kernel_descriptor);
cudnnDestroyConvolutionDescriptor(convolution_descriptor);

cudnnDestroy(cudnn);

 printf("..............12\n");

}
