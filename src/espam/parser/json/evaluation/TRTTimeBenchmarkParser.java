package espam.parser.json.evaluation;

import com.google.gson.JsonArray;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import espam.datamodel.graph.cnn.Layer;
import espam.datamodel.graph.cnn.Network;
import espam.parser.json.JSONParser;
import espam.utils.fileworker.FileWorker;

import java.util.Vector;

public class TRTTimeBenchmarkParser {
    /**
     * Parse time evalution of a CNN, obtained from execution of a CNN on GPU,
     * implemented with TensoRT, and executed on the hardware plaftorm GPU
     * @param benchmarkPath path to *.json benchmark, generated by TensoRT GPU eval code
     * @return hashmap<Layer, Double time evaluation (ms)>
     */
    public static TimeEvalBenchmark parseGPUTimeBenchmark(String benchmarkPath, Network dnn){
        return parseTimeBenchmark(benchmarkPath, dnn,"GPU");
    }

    /**
     * Parse time evalution of a CNN, obtained from execution of a CNN,
     * implemented with TensoRT/ARMCL on the hardware plaftorm
     * @param benchmarkPath path to *.json benchmark, generated by TensoRT/ARMCL eval code
     * @return hashmap<Layer, Double time evaluation (ms)>
     */
    public static TimeEvalBenchmark parseTimeBenchmark(String benchmarkPath, Network dnn, String processorName){
        TimeEvalBenchmark benchmark = new TimeEvalBenchmark();
        try {
            _initRecords(dnn, benchmark);

            //read .json benchmark
            String strJSON = FileWorker.read(benchmarkPath);
            JsonObject JSONbenchmark = (JsonObject) JSONParser.getInstance().fromJson(strJSON, JsonObject.class);
            Vector<String> JSONrecordNames = getEvalRecordNames(JSONbenchmark);
            Vector<Double> JSONrecordTimes = getEvalRecordTimes(processorName, JSONbenchmark);

            //update records with time evals, extracted from the .json benchmark
            _addIODataEvals(dnn, benchmark);
            _addPrimaryEvals(benchmark, JSONrecordNames, JSONrecordTimes);
            _addSecondaryEvals(benchmark, JSONrecordNames, JSONrecordTimes);
            _processParallelBranches(benchmark);
        }
        catch (Exception e){
            System.err.println("Time evaluation " + benchmarkPath + " parsing error: " + e.getMessage());
        }
        return benchmark;
    }

    private static void _initRecords(Network dnn, TimeEvalBenchmark bm){
        for (Layer layer: dnn.getLayers()){
            TimeEvalRecord record = new TimeEvalRecord(layer);
            bm.addRecord(record);
        }

    }

    /** Add evaluations for input/output data layers. I/O data layers are
     * not evaluated
     * @param bm benchmark
     */
    private static void _addIODataEvals(Network dnn, TimeEvalBenchmark bm){
        Layer inp = dnn.getInputLayer();
        TimeEvalRecord inpRecord = bm.findRecord(inp);
        _addIODataEval(inpRecord);
        Layer outp = dnn.getOutputLayer();
        TimeEvalRecord outpRecord = bm.findRecord(outp);
        _addIODataEval(outpRecord);
    }

    /** Add evaluations for input/output data layers. I/O data layers are
     * not evaluated
     * @param record record with I/O data eval
     */
    private static void _addIODataEval(TimeEvalRecord record){
        record.record = "none";
        record.timeEval = 0.0;
        record.recordSet = true;
    }

    /** Add evaluations of primary layers (those, that cannot be merged with
     * predcessing layers). Mostly, primary layers are Convolution and Gemm/Matmul layers.
     * @param bm benchmark
     * @param JSONrecordNames record names, extracted from .json
     * @param JSONrecordTimes time evaluations, extracted from .json
     */
    private static void _addPrimaryEvals(TimeEvalBenchmark bm, Vector<String> JSONrecordNames, Vector<Double> JSONrecordTimes){
        for (TimeEvalRecord record: bm.records){
            if(!record.recordSet){
                Integer evalRecordId = _findEvalRecordIdPrimary(record.layer.getName(), JSONrecordNames);
                if (evalRecordId!=-1){
                    record.record = JSONrecordNames.elementAt(evalRecordId);
                    record.timeEval = JSONrecordTimes.elementAt(evalRecordId);
                    record.recordSet = true;
                }
            }
        }

    }

    private static Integer _findEvalRecordIdPrimary(String layerName, Vector<String> recordNames){
        String recordName;
        for (Integer id=0; id < recordNames.size(); id++){
            recordName = recordNames.elementAt(id);
            if (recordName.startsWith(layerName))
                return id;
        }
        return -1;
    }

    /** Add evaluations of secondary layers (those, that were merged with
     * predcessing layers by TensorRT). Mostly, secondary layers are RelU, BN, Add and Concat layers.
     * @param bm benchmark
     * @param JSONrecordNames record names, extracted from .json
     * @param JSONrecordTimes time evaluations, extracted from .json
     */
    private static void _addSecondaryEvals(TimeEvalBenchmark bm, Vector<String> JSONrecordNames, Vector<Double> JSONrecordTimes){
        for (TimeEvalRecord record: bm.records){
            if(!record.recordSet){
                Integer evalRecordId = _findEvalRecordIdSecondary(record.layer.getName(), JSONrecordNames);
                if (evalRecordId!=-1){
                    record.record = JSONrecordNames.elementAt(evalRecordId);
                    //TODO: for now time of all merged layers is set to 0.
                    record.timeEval = 0.0;
                    record.recordSet = true;
                }
            }
        }

    }

    private static Integer _findEvalRecordIdSecondary(String layerName, Vector<String> recordNames){
        String recordName;
        for (Integer id=0; id < recordNames.size(); id++){
            recordName = recordNames.elementAt(id);
            if (recordName.contains(layerName))
                return id;
        }
        return -1;
    }

    /**
     * Find all record names in eval
     * @param benchmark
     * @return
     */
    private static Vector<String> getEvalRecordNames(JsonObject benchmark){
        Vector<String> layerNamesStr = new Vector<>();
        JsonArray layerNames = benchmark.get("layers").getAsJsonArray();
        for (JsonElement layerName: layerNames) {
            String layerNameStr = layerName.getAsString();
            layerNamesStr.add(layerNameStr);
        }
        return layerNamesStr;
    }

    /**
     * Find all time evals in benchmark
     * @param benchmark
     * @param processorName processor name
     * @param benchmark
     * @return
     */
    private static Vector<Double> getEvalRecordTimes(String processorName, JsonObject benchmark){
        Vector<Double> evals = new Vector<>();
        try {
            JsonArray evalElements = benchmark.get(processorName).getAsJsonArray();
            for (JsonElement evalElem : evalElements) {
                Double eval = evalElem.getAsDouble();
                evals.add(eval);
            }
        }
        catch (Exception e){ System.out.println("eval record times parsing error: " + e.getMessage());}
        return evals;
    }


    /**
     * Process benchmarks, that described several (parallel) nodes, merged into one node
     * by tensorrt
     * @param benchmark benchmark
     */
    private static void _processParallelBranches(TimeEvalBenchmark benchmark){
        Vector<String> processedBranches = new Vector<>();
        for(TimeEvalRecord record: benchmark.records){
            if(_isParalleldBranch(record.record)){
                if (!processedBranches.contains(record.record))
                {
                    _processParallelBranch(benchmark, record.record);
                    processedBranches.add(record.record);
                }
            }
        }
    }

    /**
     * Process a number of nodes (parallel branches), merged into one computational node by TensorRT
     * @param benchmark benchmark
     * @param paralleBranchRecordName record name for the merged node (from .json eval file)
     */
    private static void _processParallelBranch(TimeEvalBenchmark benchmark, String paralleBranchRecordName){
        Vector<TimeEvalRecord> mergedRecords = benchmark.getRecordsWithRecordName(paralleBranchRecordName);
        if(mergedRecords.size() >0) {
            Vector<Double> complexityShares = _getMergedNodesComplexityShares(mergedRecords);
            Double totalMergedNodesTime = mergedRecords.elementAt(0).timeEval;
            for (Integer id=0; id<mergedRecords.size(); id++) {
                Double complexityShare = complexityShares.elementAt(id);
                TimeEvalRecord record = mergedRecords.elementAt(id);
                record.timeEval = totalMergedNodesTime * complexityShare;
            }
        }
    }

    /**
     * Get share of operational complexity (0 <=x <=1) for every record in a merged parallel branch
     * @param mergedRecords merged node records
     * @return share of operational complexity (0 <=x <=1) for every record in a merged parallel branch
     */
    private static Vector<Double> _getMergedNodesComplexityShares(Vector<TimeEvalRecord> mergedRecords){
        Vector<Long> mergedRecordComplexities = new Vector<>();
        Vector<Double> complexityShares = new Vector<>();
        Long totalComplexity = 0l;
        for (TimeEvalRecord record: mergedRecords) {
            Long complexity = record.layer.getNeuron().getOperator().getTimeComplexity();
            mergedRecordComplexities.add(complexity);
            totalComplexity += complexity;
        }

        for (Long complexity: mergedRecordComplexities){
            Double complexityShare = complexity.doubleValue()/totalComplexity.doubleValue();
            complexityShares.add(complexityShare);
        }
        return complexityShares;
    }


    /**
     * Checks if record describes a number of parallel branches,
     * merged into one computational node by TensorRT
     * @param recordName record name
     * @return true, if record describes a number of parallel branches,
     * merged into one computational node by TensorRT
     */
    private static boolean _isParalleldBranch(String recordName){
        return recordName.contains(" || ");
    }
}
