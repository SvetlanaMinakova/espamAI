package espam.visitor.pthread.h;
import espam.datamodel.graph.cnn.neurons.neurontypes.NeuronType;
import espam.datamodel.graph.csdf.CSDFNode;
import espam.datamodel.graph.csdf.CSDFPort;
import espam.datamodel.graph.csdf.datasctructures.MemoryUnit;
import espam.datamodel.graph.csdf.datasctructures.Tensor;
import espam.visitor.pthread.weights.WeightsLoader;
import espam.visitor.sesame.h.HSDFGVisitor;
import espam.utils.fileworker.FileWorker;

import java.util.Vector;

public class HSDFGVisitorPthread extends HSDFGVisitor{

     /**
     * generate main class template contains application control logic
     */
    public void generateMainClassTemplate(String dir){
        try {
            _printStream = FileWorker.openFile(dir, _mainClassName, "h");
            _writeMainClassHBeginning(_mainClassName);
            _writeCommonEnd(_mainClassName);
            _printStream.close();
        }
        catch (Exception e){
            System.err.println(".cpp file creation error for " + _mainClassName + " " + e.getMessage());
        }
    }

         /**
     * generate main class template contains R/W primitives description
     * and other common stuff.
     */
    public void generateFuncClassTemplate(String dir){
        try {
            _printStream = FileWorker.openFile(dir, _funcClassName, "h");
            _writeFuncClassHBeginning(_funcClassName);
            _writeFunctions();
            _writeCommonEnd(_funcClassName);
            _printStream.close();
        }
        catch (Exception e){
            System.err.println(".cpp file creation error for " + _funcClassName + " " + e.getMessage());
        }
    }

     /**
     * Call .h visitor of base class template
     * @param dir target directory for templates
     */
     public void generateBaseClassTemplate(String dir){
         String className = "csdfNode";
         try {
             _printStream = FileWorker.openFile(dir, className, "h");
              String name = className;
             _printStream.println("// File automatically generated by ESPAM");
             _printStream.println("");_printStream.println("#ifndef " + name + "_H");
             _printStream.println("#define " + name + "_H");
             _printStream.println("#include <string>");
             _printStream.println("");
             _printStream.println("class " + name + "{");
             _printStream.println("public:");
             _prefixInc();
             _printStream.println(_prefix + name + "();");
             _printStream.println(_prefix + "virtual ~" + name + "();");
             _printStream.println(_prefix + "//abstract main function");
             prefixInc();
             _printStream.println(_prefix + "virtual void main(void *threadarg) = 0;");
             prefixDec();

             _writeCommonEnd(className);

         }
         catch (Exception e){
             System.err.println(".h file creation error for " + className + ". " + e.getMessage());
         }
     }

     /**
     * Call .h visitor of base class template
     * @param dir target directory for templates
     */
     public void generateDataLoadClassTemplate(String dir){
         try {
             _printStream = FileWorker.openFile(dir,_loadWeightsClassName, "h");
              String name = _loadWeightsClassName;
             _printStream.println("// File automatically generated by ESPAM");
             _printStream.println("");_printStream.println("#ifndef " + name + "_H");
             _printStream.println("#define " + name + "_H");
             _printStream.println("#include <string>");
             _printStream.println("");
             _printStream.println("class " + name + "{");
             _printStream.println("public:");
             _prefixInc();
             _printStream.println(_prefix + name + "();");
             _printStream.println(_prefix + "virtual ~" + name + "();");
             _printStream.println(_prefix + "void data_load_from_numpy(std::string srcpathprefix, int partition_id, int partition_size, int start, int shift, " + _IODatatype + "* dst);");
             _writeCommonEnd(_loadWeightsClassName);

         }
         catch (Exception e){
             System.err.println(".h file creation error for " + _loadWeightsClassName + ". " + e.getMessage());
         }
     }

       /**
     * Call .h visitor
     * @param y CSDF graph node
     * @param dir target directory for templates
     */
      @Override
     public void callVisitor(CSDFNode y, String dir){
         try {
             _printStream = FileWorker.openFile(dir, y.getName(), "h");
             _writeCommonBeginning(y.getName(),_getBaseClassName(y));

             _printStream.println(_prefix + "const int neurons = " + y.getKernelsNum() + ";");
             _writeFIFOsizes(y);

             _writeContainerTemplates(y);

             //TODO REFACTORING
             if(y.getName().toLowerCase().contains("concat")) {
                 _writeIOptsAndLengths(y);
             }

             /** write specific data*/
             _printStream.println(_prefix + "//specific node parameters and functions");
             _writeCommonEnd(y.getName());

         }
         catch (Exception e){
             System.err.println(".h file creation error for " + y.getName() + ". " + e.getMessage());
         }
     }

         /**
     * Write container templates for each container, associated with the node
     * @param node SDF graph node
     */
    @Override
    protected void _writeDNNRefinedContainerTemplates(CSDFNode node){
        for(CSDFPort inport: node.getNonOverlapHandlingInPorts()){
                MemoryUnit mu = inport.getAssignedMemory();
                if (mu!=null) {
                    _printStream.println(_prefix + "const int " + mu.getName() +
                                "_dims = " + mu.getDimensionality() + ";");
                    _writeArrWithDimsLinear(mu.getShape(),mu.getName(),mu.getTypeDesc());
                    //_writeTensorToCPPArrayDefinition(mu.getShape(),mu.getName(),mu.getTypeDesc());
                }
        }

        /** define only distinct out ports*/
        Vector<String> defined = new Vector<>();
        for(CSDFPort outport: node.getNonOverlapHandlingOutPorts()){
                MemoryUnit mu = outport.getAssignedMemory();
                if (mu!=null) {
                    if(!defined.contains(mu.getName())) {
                        _printStream.println(_prefix +"const int " + mu.getName() +
                                "_dims = " + mu.getDimensionality() + ";");
                         //_writeTensorToCPPArrayDefinition(mu.getShape(), mu.getName(), mu.getTypeDesc());
                        _writeArrWithDimsLinear(mu.getShape(),mu.getName(),mu.getTypeDesc());
                        defined.add(mu.getName());
                    }
                }
        }
        defined.clear();

        /** define weights, if any*/
        MemoryUnit weights = node.getMemoryUnit("weights");
        if(weights!=null){
            _writeArrWithDimsLinear(weights.getShape(), weights.getName(), weights.getTypeDesc());
           //_writeTensorToCPPArrayDefinitionWeights(weights.getShape(), weights.getName(), weights.getTypeDesc());
        }

        /** define biases, if any*/
        MemoryUnit bias = node.getMemoryUnit("bias");
        if(bias!=null){
             _writeBiasLinear(bias.getShape(),"bias",bias.getTypeDesc());
        }

        /** define constant parameters, if any*/
        Vector<MemoryUnit> constParams = node.getUnitParams();
        if(constParams.size()>0) {
            _printStream.println("//const parameters");
            for (MemoryUnit mu : constParams) {
                _printStream.println(_prefix + "const " + mu.getTypeDesc() + " " + mu.getName() + " = " + mu.getUnitParamDesc() + ";");
            }
        }

    }

  /**
     * Get C++ definition of static linear array,
     * corresponding to  espam. Tensor
     * @param tensor shape of weights (espam. Tensor)
     * @param arrname name of the array
     * @param typeDesc description of array type;
     * @return C++ description of static multidimensional array,
     * corresponding to  espam. Tensor
     */
    public void _writeArrWithDimsLinear(Tensor tensor, String arrname, String typeDesc){
        if(Tensor.isNullOrEmpty(tensor))
            return;

        _printStream.println(_prefix + "//"+ arrname +" array definition");
        _prefixInc();
        int tensorDimensionality = tensor.getDimensionality();
       // int revId = tensorDimensionality-1;
        for (int i =0;i< tensorDimensionality; i++)
            _printStream.println(_prefix + "const int " + arrname + "_dim_" + i +" = " +tensor.getDimSize(i)+";");

        _printStream.println(_prefix + "const int " + arrname + "_len = " +tensor.getElementsNumber()+";");
        _printStream.println();

        /** static array definition*/
        int size = tensor.getElementsNumber();
           _writeEmptyLinearArr(arrname,typeDesc,size);

        prefixDec();
        _printStream.println("");
    }

    /**
     * Define linear bias
     * @param tensor shape of bias (espam. Tensor)
     * @param arrname name of the array
     * @param typeDesc description of array type;
     */
     public void _writeBiasLinear(Tensor tensor, String arrname, String typeDesc){
        int size = tensor.getElementsNumber();
        _writeEmptyLinearArr(arrname,typeDesc,size);
        _printStream.println(_prefix + "const int " + arrname + "_len = " + size + ";");
     }

    /**
     * Write empty weights moc
     * @param name name of the array
     * @param typeDesc description of array type;
     */
    private void _writeEmptyLinearArr(String name, String typeDesc, int size){
        _printStream.println(_prefix + typeDesc + " " + name + "[" + size + "] = {0}; ");
    }


    /**
     * Write input/output ports data pointers
     * @param y CSDF node
     */
     private void _writeIOptsAndLengths(CSDFNode y){
         _printStream.println(_prefix + "//I/O ptrs and lengths");
         prefixInc();
         for(CSDFPort inport:y.getNonOverlapHandlingInPorts()){
             _writeIOpt(inport.getAssignedMemory());
         }

         CSDFPort outport = y.getNonOverlapHandlingOutPorts().elementAt(0);
         if(outport!=null)
             _writeIOpt(outport.getAssignedMemory());
         prefixDec();

     }

     /**
     * Write data pointer
     * @param mu MemoryUnit
     */
     private void _writeIOpt(MemoryUnit mu){
         if(mu==null)
             return;
         try {
             _printStream.print(_prefix + mu.getTypeDesc() + "* " + mu.getName() + "_ptr = &" + mu.getName() + "[0];");
             _printStream.println("");

         }
         catch (Exception e){
             System.err.println( mu.getName()+ " memory unit ptr creation error: " + e.getMessage());
         }
     }


    /**
     * Begin a header file with common beginning
     * @param  className name of the corresponding C++ class
     */
    @Override
    public void _writeCommonBeginning(String className, String baseClassName ) {

         String name = className;
        _printStream.println("// File automatically generated by ESPAM");
        _printStream.println("");
        _printStream.println("#ifndef " + name + "_H");
        _printStream.println("#define " + name + "_H");
        _printStream.println("#include \"" + _baseClassName + ".h\"");
        _printStream.println("#include <map>");
        _printStream.println("#include <vector>");
        if(_generateDNNFuncNA)
            _printStream.println("#include \"types2.h\"");
        _printStream.println("");
        _printStream.println("class " + name +" : public " + _baseClassName +  "{");
        _printStream.println("public:");
        _prefixInc();
        _printStream.println(_prefix + name + "();");
        _printStream.println(_prefix + "virtual ~" + name + "();");
        _printStream.println("");
        _printStream.println(_prefix + "void main(void *threadarg) override;");
        _printStream.println(_prefix + "// specific const parameters definition");
        _printStream.println(_prefix + "std::map<std::string,int> int_params;");

        _prefixDec();
    }

    public void _writeMainClassHBeginning(String className) {

         String name = className;
        _printStream.println("// File automatically generated by ESPAM");
        _printStream.println("");
        _printStream.println("#ifndef " + name + "_H");
        _printStream.println("#define " + name + "_H");
        // Include specific headers
        _printStream.println("#include <stdlib.h>");
        _printStream.println("#include <iostream>");
        _printStream.println("#include <vector>");
        _printStream.println("#include \"" + _baseClassName + ".h\"");
        _printStream.println("#include \""+_funcClassName+".h\"");
        _printStream.println("#include \"types.h\"");
        _printStream.println("");
        _printStream.println("class " + name + " {");
        _printStream.println("public:");
        _prefixInc();
        _printStream.println(_prefix + name + "();");
        _printStream.println(_prefix + "virtual ~" + name + "();");
        _printStream.println("");
        _printStream.println("// list of available nodes");
        _printStream.println(_prefix + "static std::map< std::string,csdfNode* > nodes;");
        _printStream.println("");
        _printStream.println(_prefix + "void main();");
        _printStream.println();
        _printStream.println("// Call of the specific node ");
        _printStream.println(_prefix + "static void run_node(std::string node_name);");
        _prefixDec();
    }

    public void _writeFuncClassHBeginning(String className) {
         String name = className;
        _printStream.println("// File automatically generated by ESPAM");
        _printStream.println("");
        _printStream.println("#ifndef " + name + "_H");
        _printStream.println("#define " + name + "_H");
        // Include specific headers
        _printStream.println("#include <stdlib.h>");
        _printStream.println("#include <iostream>");
        _printStream.println("#include <string>");
        _printStream.println("#include <vector>");
        _printStream.println("#include \"types.h\"");
        if(_generateDNNFuncNA) {
            _printStream.println("#include \"types2.h\"");
            _printStream.println("#include \"dnnFunc.h\"");
        }

        _printStream.println("");
        _printStream.println("class " + name + " {");
        _printStream.println("public:");
        _prefixInc();
        _printStream.println(_prefix + name + "();");
        _printStream.println(_prefix + "virtual ~" + name + "();");
        _prefixDec();
    }

    /**
     * Define application main class functions
     */
    protected void _writeFunctions(){
        _writeTransposeFunction();

        _printStream.println("");
        _printStream.println(_prefix + "// Execution function communication moc");
        prefixInc();
        _writeCommunicationMoc();
        prefixDec();

        _printStream.println(_prefix + "// Execution function primitive");
        prefixInc();
        _writeExecPrimitiveMoC();
        _writeExecPrimitive();
        prefixDec();

        //
        _printStream.println("");
        _printStream.println(_prefix + "//Data shift function (for shifting overlapping data in I/O arrays)");
        prefixInc();
        _writeCPULine();
        _printStream.println();
        _writeShiftFunctions();
        _printStream.println("");
        _writePrintFunctions();
        _writeGetBufFunc("src");
        _writeGetBufFunc("dst");
        prefixDec();
    }

    /**Execution function communication moc*/
    private void _writeCommunicationMoc(){
        _printStream.println(_prefix + "static void communication_moc("+ _IODatatype + "* input, "+ _IODatatype + "* output, int inp_len, int outp_len);");
    }

    /**
     * Print function of getting buffer from vector of buffers
     */
    protected void _writeGetBufFunc(String bufPrefix){
     _printStream.println(_prefix + "static fifo_buf* get_buf_by_" + bufPrefix +
     " (std::string name, std::vector<fifo_buf>& fifos);");
    }


    /** Write line copy function*/
    protected void _writeCPULine(){
         _printStream.println(_prefix + "// line copy function, type: " + _IODatatype);
         _printStream.println(_prefix + "static void cpy_2D_data_line(const int &data_w, "+
                 _IODatatype + " *src,"+ _IODatatype + " *dst,"+" const int &line_id);");
    }


    /**
     * Write shift function (for shifting overlapping data in I/O arrays)"
     * TODO refactoring: shift(tensor)
     */
    protected void _writeTransposeFunction(){
        _printStream.println(_prefix + "// transpose matrix, data type: " + _IODatatype);
        _printStream.println(_prefix + "static void transpose(" + _IODatatype +" *input, int inp_h, int inp_w);");
    }

    /**
     * Write shift function (for shifting overlapping data in I/O arrays)"
     * TODO refactoring: shift(tensor)
     */
    protected void _writeShiftFunctions(){
        _printStream.println(_prefix + "// matrix shift functions, type: " + _IODatatype);
        _printStream.println(_prefix + "static void shift_2D(const int &h, const int &w, "+ _IODatatype + " *x, const int &stride);");
        _printStream.println(_prefix + "static void shift_3D(const int &d, const int &h, const int &w, "+ _IODatatype + " *x, const int &stride);");
    }

    /**
     * Write matrix print functions
     * TODO refactoring: print(matrix)
     */
    protected void _writePrintFunctions(){
        _printStream.println(_prefix + "// matrix print functions, type: " + _IODatatype);
        _printStream.println(_prefix + "static void print_2D (const int &h, const int &w, "+ _IODatatype + " *x);");
        _printStream.println(_prefix + "static void print_3D (const int &d, const int &h, const int &w, "+ _IODatatype + " *x);");
        _printStream.println(_prefix + "static void show_val("+ _IODatatype + " *x, int xlen, int num);");
    }



    /**
     * Write r/w primitive functions templates
     */
    protected void _writeRWPrimitives(){
        for (int dim=1;dim <=_maxPrimitiveDimensionality; dim++){
         _printStream.println(_prefix +"// " + dim + "D");
          /** external r/w*/
            _writeMocRWPrimitive("read" + _externalRWPostfix ,dim);
            _writeMocRWPrimitive("write"+ _externalRWPostfix ,dim);
        }
    }

    /**
     * Write moc of R/W primitive
     * @param primitiveName name of the primitive: read or write
     * @param dim primitive dimensionality
     */
    protected void _writeMocRWPrimitive(String primitiveName, int dim){
        _printStream.println(_prefix + "static void " +
                    primitiveName + "_"+ dim + "D " +
                    "(void* fifo, void* memobj_cpu, int len, int fifo_size);");

    }

      /**
     * Write execution function primitive
     */
    protected void _writeExecPrimitiveMoC(){
        _printStream.println(_prefix + "static void execute (std::string function);");
    }

    /**
     * Write execution function primitive
     */
    protected void _writeExecPrimitive(){
        _printStream.println(_prefix + "static void execute (std::string function," +
                _IODatatype +"* input, " + _paramDataType + "* weights, "
                +_IODatatype + "* output," + _paramDataType + "* bias, const int* pads, std::map<std::string,int>* int_params_ptr );");
    }

    /**
     * Write FIFO sizes for CSDF node
     * @param node CSDF node
     */
    protected void _writeFIFOsizes(CSDFNode node){
        _printStream.println("");
        _printStream.println(_prefix + "//FIFO sizes");
        prefixInc();
        for(CSDFPort inport: node.getNonOverlapHandlingInPorts())
             _printStream.println(_prefix + "int " + inport.getName() + "_fifo_size;");
        for(CSDFPort outport: node.getNonOverlapHandlingOutPorts())
             _printStream.println(_prefix + "int " + outport.getName() + "_fifo_size;");
        prefixDec();
        _printStream.println("");
    }

     /**
     * Get C++ definition of static multidimensional array,
     * corresponding to  espam. With Tensor dimensions, descibed as const ints
     * @param tensor espam. Tensor
     * @param name name of the array
     * @param typeDesc description of array type;
     * @return C++ description of static multidimensional array,
     * corresponding to  espam. Tensor
     */
     @Override
    public void _writeTensorToCPPArrayDefinition(Tensor tensor, String name, String typeDesc){
        if(Tensor.isNullOrEmpty(tensor))
            return;

        _printStream.println(_prefix + "//"+ name +" array definition");
        _prefixInc();
        int tensorDimensionality = tensor.getDimensionality();
       // int revId = tensorDimensionality-1;
        for (int i = tensorDimensionality-1; i>=0; i--)
            _printStream.println(_prefix + "const int " + name + "_dim_" + (tensorDimensionality-i-1) +" = " +tensor.getDimSize(i)+";");

        _printStream.println(_prefix + "const int " + name + "_len = " +tensor.getElementsNumber()+";");

        StringBuilder defsb = new StringBuilder(typeDesc);
        defsb.append(" ");
        defsb.append(name);

        for (int i = tensorDimensionality-1; i>=0; i--)
            defsb.append("[" + tensor.getDimSize(i) + "]");

          /** static array definition*/
        defsb.append(" = ");

        for (int i = 0 ;i < tensorDimensionality; i++)
             defsb.append("{");

        defsb.append("0");

        for (int i = 0 ;i < tensorDimensionality; i++)
             defsb.append("}");

        defsb.append(";");

        _printStream.println(_prefix + defsb.toString());
        prefixDec();
        _printStream.println("");
    }



///////////////////////////////////////////////////////////////////
    ///                standard class templates                    ///

    /**
     * FIFO class - describes FIFO communication buffer between two nodes
     * @param dir directory to generate the class file
     */
     public void generateFIFOClassTemplate(String dir){
        try {
            _printStream = FileWorker.openFile(dir,"fifo", "h");
            _printStream.println("//File automatic generated by espamAI");
            _printStream.println("");
            _printStream.println("void writeSWF_CPU(void* fifo, void* memobj_cpu, int len, int fifo_size);");
            _printStream.println("");
            _printStream.println("void readSWF_CPU(void* fifo, void* memobj_cpu, int len, int fifo_size);");
            _printStream.println("");
            _printStream.println("int FIFOisFull(void *fifo);");
            _printStream.println("");
            _printStream.println("int FIFOisEmpty(void *fifo);");
            _printStream.println("");
            _printStream.println("void setaffinity(int core);");
            _printStream.println("");
            _printStream.close();
        }
        catch (Exception e){
            System.err.println(".h file creation error for " + "fifo" + " " + e.getMessage());
        }
    }

    /**
     * Generate used types class
     * @param dir directory to generate the class file
     */
    public void generatetypesClassTemplate(String dir){
        try {
            _printStream = FileWorker.openFile(dir,"types", "h");
            _printStream.println("//File automatic generated by espamAI");
            _printStream.println("");
            _printStream.println("#ifndef pthread_H");
            _printStream.println("#define pthread_H");
            _printStream.println("");
            _printStream.println("#include <pthread.h>");
            _printStream.println("#include <vector>");
            _printStream.println("#include <cstddef>");
            _printStream.println("#include <string>");
            _printStream.println("#include <memory>");
            _printStream.println("#include <map>");
            _printStream.println("");
            _printStream.println("");
            _printStream.println("/** description of buffer of one FIFO channel*/");
            _printStream.println("struct fifo_buf{");
            _printStream.println("\tstd::string src; //fifo name");
            _printStream.println("\tstd::string dst; //fifo name");
            _printStream.println("\tvoid* fifo; //ptr to shared memory");
            _printStream.println("\tint fifo_size; // size of the buffer (in tokens)");
            _printStream.println("");
            _printStream.println("\tfifo_buf(void* fifo, int fifo_size, std::string src, std:: string dst){");
            _printStream.println("\t\tthis->fifo = fifo;");
            _printStream.println("\t\tthis->fifo_size = fifo_size;");
            _printStream.println("\t\tthis->src = src;");
            _printStream.println("\t\tthis->dst = dst;");
            _printStream.println("\t}");
            _printStream.println("};");
            _printStream.println("");
            _printStream.println("");
            _printStream.println("struct thread_info{");
            _printStream.println("");
            _printStream.println("  char *message;");
            _printStream.println("  pthread_t thread_id; // ID returned by pthread_create()");
            _printStream.println("  int core_id; // Core ID we want this pthread to set its affinity to");
            _printStream.println("  //references to fifos");
            _printStream.println("  std::vector<fifo_buf*> fifo_refs;");
            _printStream.println("");
            _printStream.println("  // get fifo by source");
            _printStream.println("  fifo_buf* get_fifo_buf_by_src(std::string srcname){");
            _printStream.println("\t  for (auto & fifos_elem : fifo_refs) {");
            _printStream.println("\t\t  if(srcname.compare(fifos_elem->src) == 0)");
            _printStream.println("\t\t\t  return fifos_elem;");
            _printStream.println("\t\t  }");
            _printStream.println("\t\t  return nullptr;");
            _printStream.println("  }");
            _printStream.println("");
            _printStream.println("  // get fifo by name");
            _printStream.println("  fifo_buf* get_fifo_buf_by_dst(std::string dstname){");
            _printStream.println("\t  for (auto & fifos_elem : fifo_refs) {");
            _printStream.println("\t\t  if(dstname.compare(fifos_elem->dst) == 0)");
            _printStream.println("\t\t\t  return fifos_elem;");
            _printStream.println("\t\t  }");
            _printStream.println("\t\t  return nullptr;");
            _printStream.println("  }");
            _printStream.println("");
            _printStream.println("  void add_fifo_buf_ref(fifo_buf* fifo_buf_ref){");
            _printStream.println("\t  fifo_refs.push_back(fifo_buf_ref);");
            _printStream.println("  }");
            _printStream.println("};");
            _printStream.println("");
            _printStream.println("#endif // types_H");
            _printStream.close();
        }
        catch (Exception e){
            System.err.println(".h file creation error for " + "types" + " " + e.getMessage());
        }
    }

         /**
     * Generate DNN functions class with our test CNN functions
     * @param dir directory to generate class file
     */
    public void generateDnnClassTemplate(String dir){
        try {
            _printStream = FileWorker.openFile(dir,"dnnFunc", "h");
            _printStream.println("//File automatic generated by espamAI");
            _printStream.println("");
            _printStream.println("#ifndef dnnFunc_H_");
            _printStream.println("#define dnnFunc_H_\n");
            _printStream.println("");
            _printStream.println("#include <stdlib.h>");
            _printStream.println("#include <iostream>");
            _printStream.println("#include <string>");
            _printStream.println("#include <vector>");
            _printStream.println("#include <map>");
            _printStream.println("#include \"types.h\"");
            _printStream.println("");
            _printStream.println("class dnnFunc {");
            _printStream.println("public:");
            _printStream.println("\tdnnFunc();");
            _printStream.println("\tvirtual ~dnnFunc();");
            _printStream.println("");
            _printStream.println("    static void execute_dense_block (std::string function," +_IODatatype + " * input," +_paramDataType + "* weights," +_IODatatype + "* output,"+ _paramDataType + " *bias, " + "std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_conv (" + _IODatatype + " *input, " + _paramDataType + " *weights, " + _IODatatype + " *output," + _paramDataType + " *bias, " +
                    " std::map<std::string,int>* int_params_ptr, int core_id);");
            _printStream.println("");
            _printStream.println("");
            _printStream.println("    static void execute_addconst (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_avgpool (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_concat (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_gemm (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_lrn (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_maxpool (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_matmul (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_relu (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_reshape (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_sigm (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("    static void execute_thn (" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* output, std::map<std::string,int>* int_params_ptr );");
            _printStream.println("");
            _printStream.println("");
            _printStream.println("\tstatic void convolution_2d_inp_gpu(" +_IODatatype + "* input, " +_paramDataType + "* kernel, " +_IODatatype + "* output, int input_h, int input_w,");
            _printStream.println("\t\t\tint output_h,int output_w, int k_h, int k_w, int stride);");
            _printStream.println("");
            _printStream.println("\tstatic void convolution_3d_inp_gpu(" +_IODatatype + "* input, " +_paramDataType + "* kernel, " +_IODatatype + "* output, int channels, int input_h, int input_w,");
            _printStream.println("\t\t\t\tint output_h,int output_w, int k_h, int k_w, int stride);");
            _printStream.println("");
            _printStream.println("static void convolution_2d_inp_cpu(" +_IODatatype + "* input, " +_paramDataType + "* kernel, " +_IODatatype + "* output, int input_h, int input_w,");
            _printStream.println("\t\t\tint output_h,int output_w, int k_h, int k_w, int stride);");
            _printStream.println("");
            _printStream.println("\tstatic void convolution_3d_inp_cpu(" +_IODatatype + "* input, " +_paramDataType + "* kernel, " +_IODatatype + "* output," + _paramDataType +"*bias, int channels, int input_h, int input_w,");
            _printStream.println("\t\t\t\t int output_d, int output_h,int output_w, int k_h, int k_w, int stride);");
            _printStream.println("");
            _printStream.println("");
            _printStream.println("");
            _printStream.println("");
            _printStream.println("");
            _printStream.println("");
            _printStream.println("\tstatic float get_softmax_summ(" +_IODatatype + " *non_activated_stages, int input_len);");
            _printStream.println("\tstatic void init_zeros(" +_IODatatype + " *matrix, int h, int w);");
            _printStream.println("\tstatic void init_zeros(" + _IODatatype + " *matrix, int d, int h, int w);");
            _printStream.println("\tstatic void softmax(" + _IODatatype + " *non_activated_stages, int len);");
            _printStream.println("\tstatic void weight_and_sum(" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* result, int input_len);");
            _printStream.println("\tstatic void weight_and_sum(" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* result, int input_len, int output_len);");
            _printStream.println("\tstatic void weight_and_sum(" +_IODatatype + "* input, " +_paramDataType + "* weights, " +_IODatatype + "* result, " +_paramDataType + "* bias ,int input_len, int output_len);");
            _printStream.println("};");
            _printStream.println("#endif /* dnnFunc_H_ */");
            _printStream.close();
        }
        catch (Exception e){
            System.err.println(".h file creation error for " + _mainClassName + " " + e.getMessage());
        }
    }

    /** use neuraghe functions*/
    public void setGenerateFuncNA(boolean generateDNNFuncNA) {
        _generateDNNFuncNA = generateDNNFuncNA;
    }

    ///////////////////////////////////////////////////////////////////
    ///                private variables                           ///

    /** primitive postfix*/
    private static String _externalRWPostfix = "SWF_CPU";

    /** primitive postfix*/
   // private static String _internalRWPostfix = "_Internal";

    /** application main class name*/
    private static String _mainClassName = "appMain";

    /** max r/w primitives dimensionality */
    private static int _maxPrimitiveDimensionality = 3;

    /** CSDF graph node base class*/
    private static String _loadWeightsClassName = "dataLoader";

    /** CSDF graph node base class*/
    private static String _baseClassName = "csdfNode";

    /** CSDF graph node functions class*/
    private static String _funcClassName = "appFunc";

    /** DNN input/output type */
    public String _IODatatype = "int";

    /** DNN parameters type*/
    public String _paramDataType = "int";

    /** If the NA library is used*/
    private static boolean _generateDNNFuncNA = false;

}
